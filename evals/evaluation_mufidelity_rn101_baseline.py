import argparse

import os
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
from matplotlib import pyplot as plt

from xplique.wrappers import TorchWrapper
from xplique.metrics import MuFidelity

import clip

import torch
import torchvision.transforms as transforms
import torchvision.models as models

from tqdm import tqdm

from utils import *

tf.config.run_functions_eagerly(True)

gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
tf.config.experimental.set_virtual_device_configuration(
    gpus[0],
    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4048)]
)

data_transform = transforms.Compose(
        [
            transforms.Resize(
                (224,224), interpolation=transforms.InterpolationMode.BICUBIC
            ),
            # transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=(0.48145466, 0.4578275, 0.40821073),
                std=(0.26862954, 0.26130258, 0.27577711),
            ),
        ]
    )

def transform_vision_data(image_path, channel_first=False):
    """
    Input:
        image: An image read by opencv [w,h,c]
    Output:
        image: After preproccessing, is a tensor [c,w,h]
    """
    image =cv2.imread(image_path)
    
    image = Image.fromarray(image)
    image = data_transform(image)
    if channel_first:
        pass
    else:
        image = image.permute(1,2,0)
    return image.numpy()

def parse_args():
    parser = argparse.ArgumentParser(description='Deletion Metric')
    # general
    parser.add_argument('--Datasets',
                        type=str,
                        default='datasets/imagenet/ILSVRC2012_img_val',
                        help='Datasets.')
    parser.add_argument('--eval-list',
                        type=str,
                        default='datasets/imagenet/val_rn101_5k_true.txt',
                        help='Datasets.')
    parser.add_argument('--eval-number',
                        type=int,
                        default=-1,
                        help='Datasets.')
    parser.add_argument('--explanation-method', 
                        type=str, 
                        default='./submodular_results/imagenet-rn101-efficient/slico-20.0-5.0-0.01-pending-samples-12/attribution_map',
                        help='Save path for saliency maps generated by interpretability methods.')
    args = parser.parse_args()
    return args

def main(args):
    class_number = 1000
    batch = 64
    
    # data preproccess
    with open(args.eval_list, "r") as f:
        datas = f.read().split('\n')

    label = []
    input_image = []
    explanations = []

    for data in tqdm(datas[ : args.eval_number]):
        label.append(int(data.strip().split(" ")[-1]))
        input_image.append(
            transform_vision_data(os.path.join(args.Datasets, data.split(" ")[0]))
        )
        explanations.append(
            norm(np.load(
                os.path.join(args.explanation_method, data.split(" ")[0].replace(".JPEG", ".npy"))))
        )
        
    label_onehot = tf.one_hot(np.array(label), class_number)
    input_image = np.array(input_image)
    explanations = np.array(explanations)
    
    device = "cuda:1" if torch.cuda.is_available() else "cpu"
    vis_model = models.resnet101(pretrained = True)
    vis_model.eval()
    vis_model.to(device)
    print("load ResNet-101 model")
    
    model = TorchWrapper(vis_model.eval(), device)
    torch.cuda.empty_cache()

    # original
    if "attribution_map" in args.explanation_method:
        grid_size = 7
    else:
        grid_size = 9
    metric = MuFidelity(model, input_image, label_onehot, grid_size=grid_size)
    # metric = MuFidelity(model, input_image, label_onehot, batch_size=64, grid_size=10)

    mufidelity_score_org = metric(explanations.astype(np.float32))
    
    print("{} Attribution Method MuFidelity Score: {}".format(args.explanation_method.split("/")[-1], mufidelity_score_org))
    return 


if __name__ == "__main__":
    args = parse_args()
    main(args)